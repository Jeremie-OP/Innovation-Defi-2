{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\" \", \"l'\", \"l’\", \"la\", \"le\", \"les\", \"d’\", \"d'\", \"de\", \"du\", \"des\", \"une\", \"un\",\n",
    "                \"ce\", \"ces\", \"je\", \"moi\", \"mon\", \"me\", \"mes\", \"tu\", \"toi\", \"ton\", \"te\", \"tes\", \n",
    "                \"il\", \"lui\", \"son\", \"se\", \"ses\", \"nous\", \"notre\", \"nos\", \"vous\", \"votre\", \"vos\",\n",
    "                \"ils\", \"leur\", \"leurs\", \"n'\", \"ne\", \"tout\", \"être\", \"avoir\", \"deja\", \"déjà\",\n",
    "                \"ou\" ,\"où\", \"qu’\", \"qu'\", \"que\", \"qui\", \"quelle\", \"quel\", \"quelles\", \"quels\", \n",
    "                \".\", \",\", \"...\", \"sur\", \"telle\", \"tel\", \"telles\", \"tels\", \"laquelle\", \"lequel\",\n",
    "                \"laquelles\", \"lequels\", \"simplement\", \"comment\", \"quoi\", \"dont\", \"donc\", \"tant\",\n",
    "                \"jamais\", \"rarement\", \"parfois\", \"souvent\", \"toujours\", \"avec\", \"pour\", \"ici\",\n",
    "                \":\", \"(\", \")\", \"[\", \"]\", \"\\\"\", \"y\", \"et\", \"par\", \"fois\", \"peu\", \"on\", \"cela\",\n",
    "                \"mais\", \"dans\", \"en\", \"à\", \"au\", \"même\", \"là\", \"-\", \"si\", \"comme\", \"aussi\",\n",
    "                \"car\", \"parce\", \"quand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"train.pickle\", \"rb\") as infile:\n",
    "    comments_train = pickle.load(infile)\n",
    "\n",
    "with open(f\"dev.pickle\", \"rb\") as infile:\n",
    "    comments_dev = pickle.load(infile)\n",
    "\n",
    "with open(f\"test.pickle\", \"rb\") as infile:\n",
    "    comments_test = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(comments):\n",
    "    opinions = []\n",
    "    for comment in tqdm(comments.values()):\n",
    "        tokens = nlp(comment.get_comment())\n",
    "        opinion = []\n",
    "        for token in tokens:\n",
    "            opinion.append(token.lemma_)\n",
    "        opinions.append(opinion)\n",
    "    return opinions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665962/665962 [2:02:34<00:00, 90.55it/s]   \n"
     ]
    }
   ],
   "source": [
    "opinions_train = lemmatization(comments_train)\n",
    "with open(\"train_lemma.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(opinions_train, outfile)\n",
    "\n",
    "opinions_dev = lemmatization(comments_dev)\n",
    "with open(\"dev_lemma.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(opinions_dev, outfile)\n",
    "\n",
    "opinions_test = lemmatization(comments_test)\n",
    "with open(\"test_lemma.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(opinions_test, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_train = pickle.load(infile)\n",
    "\n",
    "with open(\"dev_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_dev = pickle.load(infile)\n",
    "\n",
    "with open(\"test_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_test = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(opinions):\n",
    "    tf = {}\n",
    "    for opinion in opinions:\n",
    "        for word in opinion:\n",
    "            if word in tf:\n",
    "                tf[word]+=1\n",
    "            else:\n",
    "                tf[word]=1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(tf):\n",
    "    purged = {}\n",
    "    for term, freq in tf.items():\n",
    "        if freq > 10:\n",
    "            purged[term] = freq\n",
    "    return purged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_words(opinions, common):\n",
    "    for opinion in tqdm(opinions):\n",
    "        for word in opinion[:]:\n",
    "            if word in stop_words or word not in common:\n",
    "                opinion.remove(word)\n",
    "    return opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665962/665962 [00:58<00:00, 11395.21it/s]\n",
      "100%|██████████| 100400/100400 [00:08<00:00, 11387.78it/s]\n"
     ]
    }
   ],
   "source": [
    "freq_train = get_tf(opinions_train)\n",
    "common = remove_rare_words(freq_train)\n",
    "opinions_train = remove_irrelevant_words(opinions_train, common)\n",
    "\n",
    "opinions_dev = remove_irrelevant_words(opinions_dev, common)\n",
    "\n",
    "opinions_test = remove_irrelevant_words(opinions_test, common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions = opinions_train + opinions_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_of_words(opinions):\n",
    "    word_to_id = {}\n",
    "    index = 1\n",
    "    for opinion in opinions:\n",
    "        for token in opinion:\n",
    "            if token not in word_to_id:\n",
    "                word_to_id[token] = index\n",
    "                index += 1\n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49012\n"
     ]
    }
   ],
   "source": [
    "word_to_id = create_dict_of_words(opinions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_to_bow(comment):\n",
    "    dico = {}\n",
    "    for token in comment:\n",
    "        if token in word_to_id:\n",
    "            if word_to_id[token] in dico:\n",
    "                dico[word_to_id[token]] += 1\n",
    "            else:\n",
    "                dico[word_to_id[token]] = 1\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665962/665962 [00:06<00:00, 100956.93it/s]\n",
      "100%|██████████| 100400/100400 [00:00<00:00, 112875.56it/s]\n"
     ]
    }
   ],
   "source": [
    "comments_train_bow = []\n",
    "for opinion in tqdm(opinions_train):\n",
    "    bow = comment_to_bow(opinion)\n",
    "    comments_train_bow.append(bow)\n",
    "with open(\"train_bow.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(comments_train_bow, outfile)\n",
    "\n",
    "comments_dev_bow = []\n",
    "for opinion in tqdm(opinions_dev):\n",
    "    bow = comment_to_bow(opinion)\n",
    "    comments_dev_bow.append(bow)\n",
    "with open(\"dev_bow.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(comments_dev_bow, outfile)\n",
    "\n",
    "comments_test_bow = []\n",
    "for opinion in tqdm(opinions_test):\n",
    "    bow = comment_to_bow(opinion)\n",
    "    comments_test_bow.append(bow)\n",
    "with open(\"test_bow.pickle\", \"wb\") as outfile:\n",
    "    pickle.dump(comments_test_bow, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(comments):\n",
    "    notes = []\n",
    "    for comment in comments.values():\n",
    "        note = comment.get_note().replace(\",\", \".\")\n",
    "        notes.append(int((float(note) - 0.5) * 2))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_train = get_notes(comments_train)\n",
    "notes_dev = get_notes(comments_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_svm(comments, notes, corpus):\n",
    "    with open(f\"{corpus}.svm\", \"w\") as outfile:\n",
    "        for i, comment in tqdm(enumerate(comments)):\n",
    "            outfile.write(str(notes[i]))\n",
    "            for key, value in sorted(comment.items()):\n",
    "                outfile.write(f\" {key}:{value}\")\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "665962it [00:13, 48287.74it/s]\n",
      "100400it [00:02, 49602.86it/s]\n"
     ]
    }
   ],
   "source": [
    "to_svm(comments_train_bow, notes_train, \"train\")\n",
    "to_svm(comments_dev_bow, notes_dev, \"dev\")\n",
    "to_svm(comments_test_bow, [7] * len(comments_test_bow), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results():\n",
    "    with open(\"out.txt\", \"r\") as results:\n",
    "        with open(\"leaderboard.txt\", \"w\") as predictions:\n",
    "            index = 0\n",
    "            for line in results:\n",
    "                note = str((int(line)+1)/2).replace(\".\", \",\")\n",
    "                predictions.write(f\"{comments_test[index].get_review_id()} {note}\\n\")\n",
    "                index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('AlloCinemassacre-bvMcZg92')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "896b237228f595e2f5d91b82f4ffe266262f0994f2317df1ffb02a2859af069a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
