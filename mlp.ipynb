{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\" \", \"l'\", \"l’\", \"la\", \"le\", \"les\", \"d’\", \"d'\", \"de\", \"du\", \"des\", \"une\", \"un\",\n",
    "                \"ce\", \"ces\", \"je\", \"moi\", \"mon\", \"me\", \"mes\", \"tu\", \"toi\", \"ton\", \"te\", \"tes\", \n",
    "                \"il\", \"lui\", \"son\", \"se\", \"ses\", \"nous\", \"notre\", \"nos\", \"vous\", \"votre\", \"vos\",\n",
    "                \"ils\", \"leur\", \"leurs\", \"n'\", \"n’\", \"ne\", \"tout\", \"être\", \"avoir\", \"deja\", \"déjà\",\n",
    "                \"ou\" ,\"où\", \"qu’\", \"qu'\", \"que\", \"qui\", \"quelle\", \"quel\", \"quelles\", \"quels\", \n",
    "                \".\", \",\", \";\", \"'\", \"sur\", \"telle\", \"tel\", \"telles\", \"tels\", \"laquelle\", \"lequel\",\n",
    "                \"laquelles\", \"lequels\", \"simplement\", \"comment\", \"quoi\", \"dont\", \"donc\", \"tant\",\n",
    "                \"jamais\", \"rarement\", \"parfois\", \"souvent\", \"toujours\", \"avec\", \"pour\", \"ici\",\n",
    "                \":\", \"(\", \")\", \"[\", \"]\", \"\\\"\", \"y\", \"et\", \"par\", \"fois\", \"peu\", \"on\", \"cela\",\n",
    "                \"mais\", \"dans\", \"en\", \"à\", \"au\", \"même\", \"là\", \"-\", \"si\", \"comme\", \"aussi\",\n",
    "                \"car\", \"parce\", \"quand\", \"c’\", \"s’\", \"s'\" \"l\", \"d\", \"..\", \"...\", \"....\", \".....\",\n",
    "                \"\\xa0\", \"  \", \"   \", \"    \", \"     \", \"      \", \"       \", \"        \", \"…\", \"…\",\n",
    "                \"j’\", \"-là\", \"-t\", \"a\", \"m’\", \"ca\", \"c\", \"l\", \"n\", \"s\", \"j\", \"x\", \"*\", \"–\", \"/\",\n",
    "                \"celui\", \"celui-ci\", \"ci\", \"quell\"\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"train_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_train = pickle.load(infile)\n",
    "\n",
    "with open(f\"dev_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_dev = pickle.load(infile)\n",
    "\n",
    "with open(\"test_lemma.pickle\", \"rb\") as infile:\n",
    "    opinions_test = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinions = opinions_train + opinions_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(opinions):\n",
    "    tf = {}\n",
    "    for opinion in opinions:\n",
    "        for word in opinion:\n",
    "            if word in tf:\n",
    "                tf[word]+=1\n",
    "            else:\n",
    "                tf[word]=1\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(tf):\n",
    "    purged = {}\n",
    "    for term, freq in tf.items():\n",
    "        if freq > 10:\n",
    "            purged[term] = freq\n",
    "    return purged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_words(opinions, common):\n",
    "    for opinion in tqdm(opinions):\n",
    "        for word in opinion[:]:\n",
    "            if word in stop_words or word not in common:\n",
    "                opinion.remove(word)\n",
    "    return opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766362/766362 [01:27<00:00, 8803.51it/s] \n"
     ]
    }
   ],
   "source": [
    "tf = get_tf(opinions)\n",
    "common = remove_rare_words(tf)\n",
    "opinions = remove_irrelevant_words(opinions, common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = get_tf(opinions)\n",
    "relevant = {k: v for k, v in sorted(tf.items(), key=lambda item: item[1], reverse=True)[:1024]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_words(opinions, relevant):\n",
    "    for opinion in tqdm(opinions):\n",
    "        for word in opinion[:]:\n",
    "            if word not in relevant:\n",
    "                opinion.remove(word)\n",
    "    return opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665962/665962 [00:05<00:00, 115871.24it/s]\n",
      "100%|██████████| 100400/100400 [00:00<00:00, 116621.12it/s]\n",
      "100%|██████████| 85847/85847 [00:02<00:00, 29533.59it/s]\n"
     ]
    }
   ],
   "source": [
    "opinions_train = remove_irrelevant_words(opinions_train, relevant)\n",
    "opinions_dev = remove_irrelevant_words(opinions_dev, relevant)\n",
    "opinions_test = remove_irrelevant_words(opinions_test, relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_of_words(opinions):\n",
    "    word_to_id = {}\n",
    "    index = 0\n",
    "    for opinion in opinions:\n",
    "        for token in opinion:\n",
    "            if token not in word_to_id:\n",
    "                word_to_id[token] = index\n",
    "                index += 1\n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "word_to_id = create_dict_of_words(opinions)\n",
    "print(len(word_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_to_vec(opinions):\n",
    "    vectors = []\n",
    "    for opinion in tqdm(opinions):\n",
    "        vector = [0] * 1024\n",
    "        for token in opinion:\n",
    "            vector[word_to_id[token]] += 1\n",
    "        vectors.append(vector)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 665962/665962 [00:22<00:00, 29398.30it/s]\n",
      "100%|██████████| 100400/100400 [00:01<00:00, 98642.53it/s]\n",
      "100%|██████████| 85847/85847 [00:00<00:00, 121198.35it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors_train = comment_to_vec(opinions_train)\n",
    "vectors_dev = comment_to_vec(opinions_dev)\n",
    "vectors_test = comment_to_vec(opinions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.pickle\", \"rb\") as infile:\n",
    "    comments_train = pickle.load(infile)\n",
    "\n",
    "with open(\"dev.pickle\", \"rb\") as infile:\n",
    "    comments_dev = pickle.load(infile)\n",
    "\n",
    "with open(\"test.pickle\", \"rb\") as infile:\n",
    "    comments_test = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes(comments):\n",
    "    notes = []\n",
    "    for comment in comments.values():\n",
    "        note = comment.get_note().replace(\",\", \".\")\n",
    "        notes.append(int((float(note) - 0.5) * 2))\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_train = get_notes(comments_train)\n",
    "notes_dev = get_notes(comments_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = numpy.array(vectors_train)\n",
    "data_dev = numpy.array(vectors_dev)\n",
    "data_test = numpy.array(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = Sequential()\n",
    "model_10.add(Dense(512, input_dim=1024, activation='relu'))\n",
    "model_10.add(Dense(256, activation='relu'))\n",
    "model_10.add(Dense(10, activation='softmax'))\n",
    "model_10.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "result_train = to_categorical(notes_train, 10)\n",
    "result_dev = to_categorical(notes_dev, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20812/20812 [==============================] - 83s 4ms/step - loss: 1.6497 - accuracy: 0.3495 - val_loss: 1.6170 - val_accuracy: 0.3606\n",
      "Epoch 2/2\n",
      "20812/20812 [==============================] - 83s 4ms/step - loss: 1.5797 - accuracy: 0.3709 - val_loss: 1.6142 - val_accuracy: 0.3644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29348165670>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.fit(data_train, result_train, epochs=2, verbose=1, validation_data=(data_dev, result_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683/2683 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model_10.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prediction(prediction):\n",
    "    with open(\"leaderboard.txt\", \"w\") as score:\n",
    "        index = 0\n",
    "        for result in prediction:\n",
    "            note = float((np.argmax(result) + 1) / 2)\n",
    "            comma = str(note).replace(\".\", \",\")\n",
    "            score.write(f\"{comments_test[index].get_review_id()} {comma}\\n\")\n",
    "            index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_prediction(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlloCinemassacre-bvMcZg92",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "896b237228f595e2f5d91b82f4ffe266262f0994f2317df1ffb02a2859af069a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
